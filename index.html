<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Temporal Activity Detection in Untrimmed Videos with Recurrent Neural Networks by imatge-upc</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Temporal Activity Detection in Untrimmed Videos with Recurrent Neural Networks</h1>
      <h2 class="project-tagline">UPC at ActivityNet Challenge CVPR 2016</h2>
      <a href="https://github.com/imatge-upc/activitynet-2016-cvprw" class="btn">View on GitHub</a>
      <a href="https://github.com/imatge-upc/activitynet-2016-cvprw/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/imatge-upc/activitynet-2016-cvprw/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="temporal-activity-detection-in-untrimmed-videos-with-recurrent-neural-networks" class="anchor" href="#temporal-activity-detection-in-untrimmed-videos-with-recurrent-neural-networks" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Temporal Activity Detection in Untrimmed Videos with Recurrent Neural Networks</h1>

<p>This is the project page of the UPC team participating in the <a href="http://activity-net.org/challenges/2016/">ActivityNet Challenge</a> for CVPR 2016.</p>

<table>
<thead>
<tr>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/activitynet-2016-cvprw/master/misc/images/alberto_montes.jpg" alt="Alberto Montes" title="Alberto Montes"></th>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/activitynet-2016-cvprw/master/misc/images/amaia_salvador.jpg" alt="Amaia Salvador" title="Amaia Salvador"></th>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/activitynet-2016-cvprw/master/misc/images/xavier_giro.jpg" alt="Xavier Giró-i-Nieto" title="Xavier Giró-i-Nieto"></th>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/activitynet-2016-cvprw/master/misc/images/santi_pascual.jpg" alt="Santiago Pascual" title="Santiago Pascual"></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">Main contributor</td>
<td align="center">Advisor</td>
<td align="center">Advisor</td>
<td align="center">Co-advisor</td>
</tr>
<tr>
<td align="center">Alberto Montes</td>
<td align="center"><a href="web-amaia">Amaia Salvador</a></td>
<td align="center"><a href="https://imatge.upc.edu/web/people/xavier-giro">Xavier Giró-i-Nieto</a></td>
<td align="center">Santiago Pascual</td>
</tr>
</tbody>
</table>

<p>Institution: <a href="http://www.upc.edu">Universitat Politècnica de Catalunya</a>.</p>

<p><img src="https://raw.githubusercontent.com/imatge-upc/activitynet-2016-cvprw/master/misc/images/upc_etsetb.jpg" alt="Universitat Politècnica de Catalunya"></p>

<h2>
<a id="abstract" class="anchor" href="#abstract" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h2>

<p>Deep learning techniques have been proven to be a great success for tasks like object detection and classification.
They have achieve huge accuracy on images but on videos where the temporal dimension is present, more new techniques are required to face task over them.</p>

<p>Activity classification and temporal activity location require new models which try to explode the temporal correlations the videos present to achieve good results on this tasks. The work presented try to face this tasks, for both activity classification and temporal activity localization using the <a href="http://activity-net.org/download.html">ActivityNet Dataset</a>.</p>

<p>This work propose to face the tasks with a two stage pipeline. The first stage is to extract video features from the C3D which exploit temporal correlations and then a RNN made up by LSTM cells which try to learn long-term correlations and returning a sequence of activities along the video that will help to classify and temporally localize activities.</p>

<h2>
<a id="dependencies" class="anchor" href="#dependencies" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

<p>This project is build using the <a href="https://github.com/fchollet/keras">Keras</a> library for Deep Learning, which can use as a backend both <a href="https://github.com/Theano/Theano">Theano</a>
and <a href="https://github.com/tensorflow/tensorflow">TensorFlow</a>.</p>

<p>We have used Theano in order to develop the project because it supported 3D convolutions and pooling required to run the C3D network.</p>

<p>For a further and more complete of all the dependencies used within this project, check out the requirements.txt provided within the project. This file will help you to recreate the exact same Python environment that we worked with.</p>

<h2>
<a id="acknowledgements" class="anchor" href="#acknowledgements" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgements</h2>

<p>We would like to especially thank Albert Gil Moreno and Josep Pujal from our technical support team at the Image Processing Group at the UPC.</p>

<table>
<thead>
<tr>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/activitynet-2016-cvprw/master/misc/images/albert_gil.jpg" alt="Albert Gil" title="Albert Gil"></th>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/activitynet-2016-cvprw/master/misc/images/josep_pujal.jpg" alt="Josep Pujal" title="Josep Pujal"></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="web-albert">Albert Gil</a></td>
<td align="center"><a href="web-josep">Josep Pujal</a></td>
</tr>
</tbody>
</table>

<h2>
<a id="contact" class="anchor" href="#contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contact</h2>

<p>If you have any general doubt about our work or code which may be of interest for other researchers, please use the <a href="https://github.com/imatge-upc/activitynet-2016-cvprw/issues">issues section</a>
on this github repo. Alternatively, drop us an e-mail at <a href="mailto:xavier.giro@upc.edu">xavier.giro@upc.edu</a>.</p>





      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/imatge-upc/activitynet-2016-cvprw">Temporal Activity Detection in Untrimmed Videos with Recurrent Neural Networks</a> is maintained by <a href="https://github.com/imatge-upc">imatge-upc</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
